{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19b0676d-e66f-47dd-b424-55f2df6fcae0",
   "metadata": {},
   "source": [
    "# Part 4: Preprocessing and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e80448-e19b-4719-8748-2300ae5b5783",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notebook Summary\n",
    "\n",
    "This notebook undergoes some basic preprocessing of the data to prepare for a baseline model and then iterating until reaching a production model. We begin by trying multiple features in a baseline model and hold all hyperparameters constant. This will allow us to do some targeted feature selection. We will then compare subsequent models to our baseline to evaluate their effectiveness in classifying a text post as belonging to either the ADHD or autism subreddit. Included in this notebook, the reader will find:\n",
    "\n",
    "* Null Baseline and Preliminary Logistic Regression Models\n",
    "* Model Iterations and Evaluations\n",
    "* Production Model\n",
    "* Notebook Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8d1ace-7749-4355-babf-ed9367a55495",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Null Baseline and Preliminary Logistic Regression Models\n",
    "\n",
    "In this section, we will develop a null and baseline model of our data. We will begin by importing all necessary libraries for our preprocessing and modeling and read in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e4b9629-c02e-4f62-a6c6-aba622eb540f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import requisite libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore', category = UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78a50f40-ee0b-4345-9bed-2a78e30760c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_word_count</th>\n",
       "      <th>post_length</th>\n",
       "      <th>selftext_lemma</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Megathread: US Medication Shortage</td>\n",
       "      <td>as many of you are aware by now the current u ...</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "      <td>2033</td>\n",
       "      <td>a many of you are aware by now the current u s...</td>\n",
       "      <td>-0.9567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you do something you're proud of? Somethin...</td>\n",
       "      <td>what success have you had this week did you ac...</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>288</td>\n",
       "      <td>what success have you had this week did you ac...</td>\n",
       "      <td>0.9633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Vyvanse poops have taken over my mornings..</td>\n",
       "      <td>i now wake up at least 1 5 hours early to ensu...</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>379</td>\n",
       "      <td>i now wake up at least 1 5 hour early to ensur...</td>\n",
       "      <td>0.6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why does someone forcing you to push through e...</td>\n",
       "      <td>i can t even explain how it hurts but it s so ...</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>304</td>\n",
       "      <td>i can t even explain how it hurt but it s so m...</td>\n",
       "      <td>-0.8755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just had an epiphany- isn’t it crazy how relig...</td>\n",
       "      <td>so my mom can believe in all her saints god je...</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>897</td>\n",
       "      <td>so my mom can believe in all her saint god jes...</td>\n",
       "      <td>-0.9856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579</th>\n",
       "      <td>Scared of old people</td>\n",
       "      <td>anyone else scared of old people when i talk t...</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>398</td>\n",
       "      <td>anyone else scared of old people when i talk t...</td>\n",
       "      <td>-0.7933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>Recommendations for blocking out noise for sleep</td>\n",
       "      <td>i have a really hard time sleeping due to even...</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>588</td>\n",
       "      <td>i have a really hard time sleeping due to even...</td>\n",
       "      <td>-0.6284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4581</th>\n",
       "      <td>Mom Refuses Access to Diagnosis Report</td>\n",
       "      <td>i 17f was diagnosed with autism and adhd aroun...</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>403</td>\n",
       "      <td>i 17f wa diagnosed with autism and adhd around...</td>\n",
       "      <td>-0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4582</th>\n",
       "      <td>Do you feel uncomfortable with everyday sounds?</td>\n",
       "      <td>i m talking about inevitable sounds as birds d...</td>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>1067</td>\n",
       "      <td>i m talking about inevitable sound a bird dog ...</td>\n",
       "      <td>0.3574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4583</th>\n",
       "      <td>Is it okay to self identify as autistic despit...</td>\n",
       "      <td>so a few months ago i went into therapy for po...</td>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "      <td>1010</td>\n",
       "      <td>so a few month ago i went into therapy for pos...</td>\n",
       "      <td>0.9925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4584 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                    Megathread: US Medication Shortage   \n",
       "1     Did you do something you're proud of? Somethin...   \n",
       "2       The Vyvanse poops have taken over my mornings..   \n",
       "3     Why does someone forcing you to push through e...   \n",
       "4     Just had an epiphany- isn’t it crazy how relig...   \n",
       "...                                                 ...   \n",
       "4579                               Scared of old people   \n",
       "4580   Recommendations for blocking out noise for sleep   \n",
       "4581             Mom Refuses Access to Diagnosis Report   \n",
       "4582    Do you feel uncomfortable with everyday sounds?   \n",
       "4583  Is it okay to self identify as autistic despit...   \n",
       "\n",
       "                                               selftext  subreddit  \\\n",
       "0     as many of you are aware by now the current u ...          0   \n",
       "1     what success have you had this week did you ac...          0   \n",
       "2     i now wake up at least 1 5 hours early to ensu...          0   \n",
       "3     i can t even explain how it hurts but it s so ...          0   \n",
       "4     so my mom can believe in all her saints god je...          0   \n",
       "...                                                 ...        ...   \n",
       "4579  anyone else scared of old people when i talk t...          1   \n",
       "4580  i have a really hard time sleeping due to even...          1   \n",
       "4581  i 17f was diagnosed with autism and adhd aroun...          1   \n",
       "4582  i m talking about inevitable sounds as birds d...          1   \n",
       "4583  so a few months ago i went into therapy for po...          1   \n",
       "\n",
       "      post_word_count  post_length  \\\n",
       "0                 319         2033   \n",
       "1                  52          288   \n",
       "2                  85          379   \n",
       "3                  62          304   \n",
       "4                 175          897   \n",
       "...               ...          ...   \n",
       "4579               77          398   \n",
       "4580              116          588   \n",
       "4581               83          403   \n",
       "4582              204         1067   \n",
       "4583              195         1010   \n",
       "\n",
       "                                         selftext_lemma  sentiment  \n",
       "0     a many of you are aware by now the current u s...    -0.9567  \n",
       "1     what success have you had this week did you ac...     0.9633  \n",
       "2     i now wake up at least 1 5 hour early to ensur...     0.6124  \n",
       "3     i can t even explain how it hurt but it s so m...    -0.8755  \n",
       "4     so my mom can believe in all her saint god jes...    -0.9856  \n",
       "...                                                 ...        ...  \n",
       "4579  anyone else scared of old people when i talk t...    -0.7933  \n",
       "4580  i have a really hard time sleeping due to even...    -0.6284  \n",
       "4581  i 17f wa diagnosed with autism and adhd around...    -0.4019  \n",
       "4582  i m talking about inevitable sound a bird dog ...     0.3574  \n",
       "4583  so a few month ago i went into therapy for pos...     0.9925  \n",
       "\n",
       "[4584 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reads in dataset\n",
    "sr_posts = pd.read_csv('./data_files/sr_posts_cleaned.csv')\n",
    "\n",
    "sr_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "593777af-398a-4333-90e1-1d7af02b55a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title               0\n",
       "selftext            7\n",
       "subreddit           0\n",
       "post_word_count     0\n",
       "post_length         0\n",
       "selftext_lemma     10\n",
       "sentiment           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nulls\n",
    "sr_posts.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "860fb119-5589-4c51-a40c-cd107f3f1f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop all null values\n",
    "sr_posts.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4267290e-8f36-4538-b892-d15204155d04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title              0\n",
       "selftext           0\n",
       "subreddit          0\n",
       "post_word_count    0\n",
       "post_length        0\n",
       "selftext_lemma     0\n",
       "sentiment          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nulls\n",
    "sr_posts.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc4b152-4179-44fa-a3b2-a25627eeec7b",
   "metadata": {},
   "source": [
    "We will start first by exploring the null baseline model, our baseline accuracy score for the majority class. This will then be used as an ongoing yardstick to compare other models moving forward. Since the data are collected fairly evenly from both subreddits, the reader will recall that we are hoping to achieve an accuracy score of at least 90% on our test set, exceeding our null baseline score by approximately 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c3ba26f-66b5-4480-b98d-e4e3f4c81f77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.500219\n",
       "0    0.499781\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displays proportion of posts belonging to each subreddit\n",
    "sr_posts['subreddit'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df8bfe5-eda8-43a9-933a-6e1f94429eef",
   "metadata": {},
   "source": [
    "According to this null model, any subsequent models must be able to guess the majority class of autism with greater than a 0.50 baseline accuracy score to ensure that they are modeling better than the null baseline accuracy.\n",
    "\n",
    "We will be looking at a couple different preliminary models of the purpose of feature selection. The goal here will be to choose different features to iterate on the same model before iterate with the final, selected features on multiple different models.\n",
    "\n",
    "Let us look at a preliminary model which uses a count vectorizer and logistic regression on the cleaned selftext with our new stop words from our EDA but without lemmatization first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55a40c2a-90f4-4c03-b472-71a7fd694502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# declares features and target variable, then train/test splits dataset\n",
    "X = sr_posts['selftext']\n",
    "y = sr_posts['subreddit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff110935-a734-4d29-bc0e-ebf4fe93adb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# builds a list of stop words including English and adding subreddit specific words\n",
    "new_stop_words = stopwords.words('english')\n",
    "incl_stop_words = ['don', 've', 'autism', 'autistic', 'adhd', 'medication', 'meds']\n",
    "for word in incl_stop_words:\n",
    "    new_stop_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16f006c7-39e0-4208-8615-d4fdebd78e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creates a pipeline for the CountVectorizer and Logistic Regression\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = new_stop_words)),\n",
    "    ('lr', LogisticRegression(max_iter = 5000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9573db8f-e059-4ff8-ab23-e10abc47d1c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creates the pipe params for pipe\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [4000, 5000],\n",
    "    'cvec__min_df': [2, 4, 6],\n",
    "    'cvec__max_df': [1.0, 0.8],\n",
    "    'lr__penalty': ['l2', None],\n",
    "    'lr__C': [0.1, 1, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d0f2d52e-1bdc-4d00-839c-d55919df062a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8131195335276967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': 4000,\n",
       " 'cvec__min_df': 6,\n",
       " 'lr__C': 0.1,\n",
       " 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs a grid search over pipe for the given params\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid=pipe_params,\n",
    "                 n_jobs = -1)\n",
    "\n",
    "# fits the grid search over our train data and prints best score and best params\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_) \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d7efd824-895f-437d-abf4-56512bfda3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Score: 0.9551020408163265\n",
      "Logistic Regression Test Score: 0.8243006993006993\n"
     ]
    }
   ],
   "source": [
    "# print training and test scores\n",
    "print(f'Logistic Regression Training Score: {gs.score(X_train, y_train)}')\n",
    "print(f'Logistic Regression Test Score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045520e1-7d33-4a32-bfcf-2f0ba15cce06",
   "metadata": {},
   "source": [
    "This logistic regression model appears to be very overfit.\n",
    "\n",
    "We will continue investigating a logistic regression model with lemmatizing and then after that, a logistic regression model with bigrams. For the purposes of comparison, we will leave parameters in the grid search the same. Again, the rationale is to determine, based on this preliminary logistic regression model, which features we should use in iterating with other models, the vectorized selftext alone, the vectorized lemmatized selftext, the vectorized selftext bigrams, or the vectorized selftext bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0629157-52a5-4e6b-acb1-e8430ae21396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# declares features and target variable, then train/test splits dataset\n",
    "X = sr_posts['selftext_lemma']\n",
    "y = sr_posts['subreddit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1dbe0eb2-abf6-4b0a-9020-4e7a40e34bf0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8206997084548104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 2,\n",
       " 'lr__C': 0.1,\n",
       " 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs a grid search over pipe for the given params\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid=pipe_params,\n",
    "                 n_jobs = -1)\n",
    "\n",
    "# fits the grid search over our train data and prints best score and best params\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_) \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b86be5ad-2e70-4012-a86a-df82759dac04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Lemmatized Training Score: 0.9565597667638484\n",
      "Logistic Regression Lemmatized Test Score: 0.8199300699300699\n"
     ]
    }
   ],
   "source": [
    "# print training and test scores\n",
    "print(f'Logistic Regression Lemmatized Training Score: {gs.score(X_train, y_train)}')\n",
    "print(f'Logistic Regression Lemmatized Test Score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d1066b-2c28-477c-95ef-98d934c162a6",
   "metadata": {},
   "source": [
    "This second preliminary model shows a slightly higher cross-validation score and incrementally lower test score. The training score is also slightly better on the lemmatized text. This would indicate that the lemmatized text might be slightly better to use as our starting features rather than simply the original text with the stop words.\n",
    "\n",
    "We will run two more iterations of this logistic regression, hold the parameters constant, one with bigrams of the original text and another with bigrams of the lemmatized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "39c5ba72-6143-4170-9028-c3a0c19b0e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# declares features and target variable, then train/test splits dataset\n",
    "X = sr_posts['selftext']\n",
    "y = sr_posts['subreddit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "be85499b-5c4b-4021-8e9d-805f33669757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creates a pipeline for the CountVectorizer and Logistic Regression\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = new_stop_words, ngram_range = (2, 2))),\n",
    "    ('lr', LogisticRegression(max_iter = 10000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dd6b0135-8c52-4397-822e-d580c1aa8612",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70932944606414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': 4000,\n",
       " 'cvec__min_df': 4,\n",
       " 'lr__C': 0.1,\n",
       " 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs a grid search over pipe for the given params\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid=pipe_params,\n",
    "                 n_jobs = -1)\n",
    "\n",
    "# fits the grid search over our train data and prints best score and best params\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_) \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1c17b1f3-f8bb-43f4-9f9f-92bd4af8ece7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Bigram Training Score: 0.88600583090379\n",
      "Logistic Regression Bigram Test Score: 0.7106643356643356\n"
     ]
    }
   ],
   "source": [
    "# print training and test scores\n",
    "print(f'Logistic Regression Bigram Training Score: {gs.score(X_train, y_train)}')\n",
    "print(f'Logistic Regression Bigram Test Score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f520b-1bd4-4718-ad10-da176cc2a886",
   "metadata": {},
   "source": [
    "The bigram features appear to be performing much more poorly than the selftext features alone, with much lower cross-validation and test scores.\n",
    "\n",
    "Finally, we shall see if lemmatized bigrams perform any better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6a53b7ae-e797-4973-aa94-effe5cb74bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# declares features and target variable, then train/test splits dataset\n",
    "X = sr_posts['selftext_lemma']\n",
    "y = sr_posts['subreddit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "903ce74c-2dd5-4415-8ef9-c85135a44ed7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7081632653061225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': 4000,\n",
       " 'cvec__min_df': 4,\n",
       " 'lr__C': 0.1,\n",
       " 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs a grid search over pipe for the given params\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid=pipe_params,\n",
    "                 n_jobs = -1)\n",
    "\n",
    "# fits the grid search over our train data and prints best score and best params\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_) \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8e63e407-c594-4b5b-aa1e-c16de08504fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Lemmatized Bigram Training Score: 0.8915451895043732\n",
      "Logistic Regression Lemmatized Bigram Test Score: 0.7027972027972028\n"
     ]
    }
   ],
   "source": [
    "# print training and test scores\n",
    "print(f'Logistic Regression Lemmatized Bigram Training Score: {gs.score(X_train, y_train)}')\n",
    "print(f'Logistic Regression Lemmatized Bigram Test Score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ee05e9-f279-4547-9ab0-e2f78f27eae7",
   "metadata": {},
   "source": [
    "Based on what we are seeing here the lemmatized bigrams perform slightly poorer than the bigrams on their own.\n",
    "\n",
    "Comparing all four preliminary logistic regression models it does appear that the lemmatized selftext will likely make the best features to use moving forward with subsequent iterations of our model. Therefore, we will keep the lemmatized selftext as our features and begin iterating with different types of models.\n",
    "\n",
    "In the next section, we shall iterate with multiple classification models using the lemmatized selftext as our features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e940a30-df8c-4825-b1e3-3944ea185b48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d130cf50-7155-4d77-bf30-007a4e72c2ff",
   "metadata": {},
   "source": [
    "For each of the following subsequent models, we will build a pipeline, specific grid search parameters, run a grid search, and then do a cursory evaluation with an accuracy score.\n",
    "\n",
    "We will begin first with the K-Nearest Neighbors Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bf921502-d1eb-45d1-b65f-481df5410500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# declares features and target variable, then train/test splits dataset\n",
    "X = sr_posts['selftext_lemma']\n",
    "y = sr_posts['subreddit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "208d14d7-c81b-44fa-a2a2-25a826d4fd8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creates a pipeline for the CountVectorizer and KNN\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = new_stop_words)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6cfab1a5-d838-49ec-9a70-6d45e2a81258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creates the pipe params for pipe\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [4000, 5000],\n",
    "    'cvec__min_df': [2, 4, 6],\n",
    "    'cvec__max_df': [1.0, 0.8],\n",
    "    'knn__n_neighbors': range(1, 51, 10),\n",
    "    'knn__metric': ['euclidean', 'manhattan']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "76793ce5-009b-4c5a-bcd0-0a1b7db4bbb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5405247813411078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': 4000,\n",
       " 'cvec__min_df': 4,\n",
       " 'knn__metric': 'euclidean',\n",
       " 'knn__n_neighbors': 1}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs a grid search over pipe for the given params\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid=pipe_params,\n",
    "                 n_jobs = -1)\n",
    "\n",
    "# fits the grid search over our train data and prints best score and best params\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_) \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a76530ec-42e6-4e96-873c-331064f71b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Training Score: 0.9991253644314869\n",
      "K-Nearest Neighbors Test Score: 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "# print training and test scores\n",
    "print(f'K-Nearest Neighbors Training Score: {gs.score(X_train, y_train)}')\n",
    "print(f'K-Nearest Neighbors Test Score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6ecbdc-43ca-4cce-b07a-4ee8d379e782",
   "metadata": {},
   "source": [
    "We can see here that the K-Nearest Neighbors are barely performing better than the baseline accuracy score based on the cross-validation score and the test score. Therefore, K-Nearest Neighbors is not going to be a useful model for the purposes of our problem statement.\n",
    "\n",
    "Let us continue with a decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3bc955ad-fc7d-414d-8dd4-6e1664f2449a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creates a pipeline for the CountVectorizer and Decision Tree\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = new_stop_words)),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "223f99a3-3772-4790-99ab-df5318da03aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creates the pipe params for pipe\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [4000, 5000],\n",
    "    'cvec__min_df': [2, 4, 6],\n",
    "    'cvec__max_df': [1.0, 0.8],\n",
    "    'dt__max_depth': [3, 5, 7], \n",
    "    'dt__ccp_alpha': [0, 0.1, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "07c75bdd-c5a9-4a4f-892b-e9ce0b7464bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7084548104956268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.8,\n",
       " 'cvec__max_features': 4000,\n",
       " 'cvec__min_df': 2,\n",
       " 'dt__ccp_alpha': 0,\n",
       " 'dt__max_depth': 7}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs a grid search over pipe for the given params\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid=pipe_params,\n",
    "                 n_jobs = -1)\n",
    "\n",
    "# fits the grid search over our train data and prints best score and best params\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_) \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "123c4fb8-03f6-47fd-8fef-48b759ffc7c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Training Score: 0.7387755102040816\n",
      "Decision Tree Test Score: 0.708916083916084\n"
     ]
    }
   ],
   "source": [
    "# print training and test scores\n",
    "print(f'Decision Tree Training Score: {gs.score(X_train, y_train)}')\n",
    "print(f'Decision Tree Test Score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87d4063-3393-4cc2-b3d4-dde29322a2e4",
   "metadata": {},
   "source": [
    "Looking at the cross-validation and test scores of approximately 0.71 each, we see that this model is definitely performing better than the KNN model above but is still performing at about the level of the bigrams used as features in the logistic regression. Therefore, we can see that the decision tree model ultimatley is not a good fit for our problem statement.\n",
    "\n",
    "Now, we shall continue with a few ensemble models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f0d22bac-d6ed-4469-a0c4-c7d989018483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a pipeline for the CountVectorizer and Decision Tree\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = new_stop_words)),\n",
    "    ('bc', BaggingClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ad4f429d-48e7-4aa3-8a4b-9c12e778885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the pipe params for pipe\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [4000, 5000],\n",
    "    'cvec__min_df': [2, 4, 6],\n",
    "    'cvec__max_df': [1.0, 0.8],\n",
    "    'bc__estimator': [LogisticRegression(max_iter = 10000), DecisionTreeClassifier()], \n",
    "    'bc__n_estimators': range(10, 31, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "724a6ae1-7c93-4250-9feb-6c18d6456af1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8137026239067054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bc__estimator': LogisticRegression(max_iter=10000),\n",
       " 'bc__n_estimators': 10,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 4}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs a grid search over pipe for the given params\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid=pipe_params,\n",
    "                 n_jobs = -1)\n",
    "\n",
    "# fits the grid search over our train data and prints best score and best params\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_) \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a585c807-9c04-416b-bb18-af73aab4bba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Training Score: 0.972594752186589\n",
      "Bagging Classifier Test Score: 0.8155594405594405\n"
     ]
    }
   ],
   "source": [
    "# print training and test scores\n",
    "print(f'Bagging Classifier Training Score: {gs.score(X_train, y_train)}')\n",
    "print(f'Bagging Classifier Test Score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc202231-5cef-4c28-a48c-00984c14ec18",
   "metadata": {},
   "source": [
    "Regarding the Bagging Classifier, we do see a rather high cross-validation scoree of 0.81 and test score of 0.82 These are close to our logistic regression scores in the preliminary model. However, they are still performing slightly worse than logistic regression, so our preliminary model remains the best classifier model so far.\n",
    "\n",
    "We will now continue with a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "418cd794-00ca-450d-86e1-668495537e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a pipeline for the CountVectorizer and Decision Tree\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = new_stop_words)),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fa4e5ac4-9ac1-4496-8707-fe751db15d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the pipe params for pipe\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [4000, 5000],\n",
    "    'cvec__min_df': [2, 4, 6],\n",
    "    'cvec__max_df': [1.0, 0.8],\n",
    "    'rf__n_estimators': range(1, 301, 100),\n",
    "    'rf__max_depth': [None, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5cabb4dd-0cce-4789-b3b3-601c69b15c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8163265306122449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': 4000,\n",
       " 'cvec__min_df': 6,\n",
       " 'rf__max_depth': None,\n",
       " 'rf__n_estimators': 201}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs a grid search over pipe for the given params\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid=pipe_params,\n",
    "                 n_jobs = -1)\n",
    "\n",
    "# fits the grid search over our train data and prints best score and best params\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_) \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6d09b96b-2ff3-489b-a1ab-46a779a03c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Training Score: 0.9991253644314869\n",
      "Random Forest Classifier Test Score: 0.8138111888111889\n"
     ]
    }
   ],
   "source": [
    "# print training and test scores\n",
    "print(f'Random Forest Classifier Training Score: {gs.score(X_train, y_train)}')\n",
    "print(f'Random Forest Classifier Test Score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b6fc80-a019-4dfb-8f86-f42b4dd818eb",
   "metadata": {},
   "source": [
    "For the random forest classifier, we also see that the cross-validation score of 0.82 and the test score of 0.81 are both very high and also super close to the logistic regression preliminary model. However, these scores are still performing somewhat less than the logistic regression, so the logistic regression is still our best model so far.\n",
    "\n",
    "Let us try one more with a boosting model, using AdaBoost ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3056f110-0513-4998-8294-cce4c3b61b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a pipeline for the CountVectorizer and Decision Tree\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = new_stop_words)),\n",
    "    ('ab', AdaBoostClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6c85da85-3437-4284-bf54-9c84f91fe1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the pipe params for pipe\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [4000, 5000],\n",
    "    'cvec__min_df': [2, 4, 6],\n",
    "    'cvec__max_df': [1.0, 0.8],\n",
    "    'ab__n_estimators': [50, 100, 150],\n",
    "    'ab__learning_rate': [0.9, 1.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fc9746fb-5429-42ee-801d-01163e21e8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7979591836734693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ab__learning_rate': 1.1,\n",
       " 'ab__n_estimators': 150,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': 4000,\n",
       " 'cvec__min_df': 2}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs a grid search over pipe for the given params\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid=pipe_params,\n",
    "                 n_jobs = -1)\n",
    "\n",
    "# fits the grid search over our train data and prints best score and best params\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_) \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a19e7240-4d94-4757-a695-bc093a5edb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Training Score: 0.8880466472303207\n",
      "AdaBoost Classifier Test Score: 0.7788461538461539\n"
     ]
    }
   ],
   "source": [
    "# print training and test scores\n",
    "print(f'AdaBoost Classifier Training Score: {gs.score(X_train, y_train)}')\n",
    "print(f'AdaBoost Classifier Test Score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fedbdd9-37e0-4070-8ef1-580c13ad9d50",
   "metadata": {},
   "source": [
    "Looking at these final scores for the AdaBoost Classifier, we can see that the cross-validation and test scores are substantially lower than the logistic regression scores. Therefore, at this point, we can safely conclude that our final production model should be the logistic regression model.\n",
    "\n",
    "We shall continue forward with the logistic regression model as our final production model with following features and hypermeters:\n",
    "\n",
    "* Features: Lemmatized Text with English and Modified Stop Words\n",
    "* Max Document Frequency: 100%\n",
    "* Maximum Features: 5,000\n",
    "* Minimum Document Frequency: 2\n",
    "* Logistic Regression C-value: 0.1\n",
    "* Logistic Regression Penalty: L2 \"Ridge\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcabc425-9717-4411-8413-ef56920433f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notebook Conclusion\n",
    "\n",
    "In this notebook, we looked at a null baseline accuracy score for the sake of comparison of all subsequent models. We then built a series of preliminary models using logistic regression and the same hyperparameters over a grid search, changing only the features used in each model to do some more specific feature selection. Then, we iterated with those selected features through six different models to compare against our null baseline and preliminary model to determine which was the best fit for our final production model. We determined that the logistic regression preliminary model outperforms the other iterated models, and we will use the logistic regression as our final production model.\n",
    "\n",
    "Now that have our final production model in the form of a logistic regression, we can begin a final evaluation of how well our model performs on other metrics besides accuracy alone. In Part 5, we will look at the other metrics including precision and recall, as well as the f1-score to determine how well how model is doing in answering our problem statement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
